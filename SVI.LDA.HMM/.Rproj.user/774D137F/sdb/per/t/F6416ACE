{
    "collab_server" : "",
    "contents" : "LDA.SVI<-function(X, # the Input data\n                  K, # the number of the topics\n                  n, # the number of the passes\n                  alpha, # the parameter of theta\n                  eta, # the parameter of beta\n                  pre, # the stop criteria\n                  topic_length# the number of top words and topics\n\n)\n{\n       library(Rcpp)\n       library(RcppArmadillo)\n       sourceCpp(file='src/LDA.cpp')\n       t=  SVI_LDA(X,K,n,alpha,eta,pre,topic_length)\n       names(t)=c(\"Lan\",\"LSS\",\"LL\",\"SSS\",\"SSSSSS\")\n       return(t)\n}\n\nTokenize<-function(Data_set, # the Input original data, which is a list data type\n                   Language = \"en\"# the language type you want to produce, defaut language is en\n                   )\n{\n     library(tokenizers);\n     tokenized_data <-tokenize_words(Data_set, stopwords = stopwords(Language));\n     return(tokenized_data);\n}\nStemming <- function(Tokenized_data)\n{\n  library(tokenizers);\n   Document_num = length(Tokenized_data);\n   Stem_data <- list(Document_num);\n   for( i in 1:length(Tokenized_data))\n   {\n      Stem_data[[i]]=wordStem(unlist(Tokenized_data[i]));\n   }\n   return (Stem_data);\n}\n\n X=list(c('home','mother','mother','house','mother',rep(\"cat\",3)),c('father','dad','cat','dad','cat','cat','cat','cat','cat','cat'))\nK=3;\nalpha=1/K;\neta=0.01;\nn=100;\npre=0.1;\nt=LDA.SVI(X,K,n,alpha=1/K,eta=0.01,pre=0.01,topic_length= 3)\ndoc_a = \"Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother.\"\ndoc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\ndoc_c = \"Some health experts suggest that driving may cause increased tension and blood pressure.\"\ndoc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\"\ndoc_e = \"Health professionals say that brocolli is good for your health.\"\ndata <- list(doc_a,doc_b,doc_c,doc_d,doc_e)\nSVI.HMM <- function( Data_sequence, # Observed data\n                     sub_length , # subchain length\n                     K,             #Hidden_state_number\n                     W_A,         # initial parameter,which controls transition matrix\n                     u,            # initial mean value\n                     k,            # initial parameter, which controls Gassuian Distribution\n                     sigma,        # initial covariance matrix\n                     v,             # initial parameter, which controls Gassuian Distribution\n                     U_A,    # Hyperparameter\n                     U_phi1, # Hyperparameter\n                     U_phi2, # Hyperperameter the same notation with the paper\n                     U_phi3, # Hyperperameter the same notation with the paper\n                     U_phi4, # Hyperperameter the same notation with the paper\n                     Pass,    # toal pass\n                     pre\n)\n{\n  Dim=length(Data_sequence[[1]])  # data_dimention\n  T = length(Data_sequence)    # data squence length T\n  P_ = matrix(rep(1/K,T*K),T);   #  Have the same meaning with paper in S10\n  q_x = matrix(rep(1/K,T*K),T);  # transition matrix, In S14 of the paper\n  alpha_forward=matrix(rep(1/K,T*K),T); # the same meaning with that in forward and backward algorithm\n  beta_backward= matrix(rep(1/K,T*K),T);\n  q_transition = array(rep(0,T*K*K),c(T,K,K)) # Equal to S15 in the paper\n  i = 0;\n  W_A_old=0\n  while(norm(W_A-W_A_old,\"F\")/norm(W_A)>=pre&&i<Pass)\n  {\n    W_A_old=W_A\n    i=i+1\n    for(j in 1:(T-sub_length+1))  # sample each subchain\n    {\n      A_ = exp(digamma(W_A)-digamma(rowSums(W_A)));# the same with S11\n      for(m in 1:K)\n      {\n        for(t in j:(j+sub_length-1))\n        {\n          # this formulate is given by you and please check it again to promise its accuracy\n          P_[t,m]= exp(-0.5*logb(2*pi)-0.5*(sum(digamma(0.5*(v[m]+1-1:Dim))))+Dim*logb(2)-logb(det(sigma[[m]]))-0.5*Dim/k[m]-0.5*v[m]*t(Data_sequence[[t]]-u[,m])%*%solve(sigma[[m]])%*%(Data_sequence[[t]]-u[,m]));\n          }\n      }\n      Eq_A = W_A/rowSums(W_A)#Get the expectation of A with q(A) density function\n      eigen_value= eigen(Eq_A)\n      pi_hat = eigen_value$vectors[,1] # corresponding to biggest eigen_value, initiate original distribution in forward algorithm\n       for(tag in j:(j+sub_length-1))  # tag means time\n      {\n        if(tag==j)\n        {\n          for(state in 1:K)\n          {\n            alpha_forward[tag,state]=crossprod(pi_hat,A_[,state])*P_[tag,state] # S12 in the paper\n          }\n          alpha_forward[tag,]= alpha_forward[tag,]/sum(alpha_forward[tag,])\n        }\n        else\n        {\n          for(state in 1:K)\n          {\n            alpha_forward[tag,state]=sum(alpha_forward[tag-1,]*A_[,state])*P_[tag,state]\n            # recursion\n          }\n          alpha_forward[tag,]= alpha_forward[tag,]/sum(alpha_forward[tag,])\n        }\n       }\n     # write.table(alpha_forward,\"alpha_forward.txt\",append = T)\n      for(tag in (j+sub_length-1):j)\n      {\n        if(tag==j+sub_length-1)\n        {\n          beta_backward [tag,]=1 # initiate\n        }\n        else\n        {\n          for(state in 1:K)\n          {\n            beta_backward[tag,state]=sum(A_[state,]*beta_backward[tag+1,]*P_[tag+1,]) #S13 ,but I think paper is wrong,and please check again\n          }\n          beta_backward[tag,]=beta_backward[tag,]/sum(beta_backward[tag,])\n        }\n      }\n    #  write.table(beta_backward,\"beta.txt\",append = T)\n      beta_original = rep(0,K) # this corresponds to beta_0, even it is no use for following caculation\n      for(state in 1:K)\n      {\n        beta_original[state]=sum(A_[state,]*beta_backward[j,]*P_[j,])\n      }\n      for(tag in j:(j+sub_length-1))  # S14 in this paper, we only need time from 1, that is from j in subchain situation.\n      {                              #Please check my idea accuracy, I think we don't need calculate t=0\n        q_x[tag,]=alpha_forward[tag,]*beta_backward[tag,]\n        q_x[tag,]= q_x[tag,]/sum(q_x[tag,]) # normalize\n      }\n    #  write.table(q_x,\"q_x.txt\",append = T)\n    #  write.table(A_,\"A_.txt\",append = T)\n    #  write.table(P_,\"P_.txt\",append = T)\n      for(tag in j:(j+sub_length-1))\n      {\n        if(tag==j) # we need pi_hat to calculate S15 in the first iteration\n        {\n          for(j_local in 1:K)\n          {\n            for(k_local in 1:K)\n            { #q_transition according to index of Xt. And S15 is wrong in my opinion. I substitute P,A with P_,A_. Check please\n              q_transition[tag,j_local,k_local]=pi_hat[j_local]*A_[j_local,k_local]*P_[tag,k_local]*beta_backward[tag,k_local];\n            }\n          }\n          q_transition[tag,,]=q_transition[tag,,]/sum(q_transition[tag,,])\n        }\n        else\n        {\n          for(j_local in 1:K)\n          {\n            for(k_local in 1:K)\n            {\n              q_transition[tag,j_local,k_local]=alpha_forward[tag-1,j_local]*A_[j_local,k_local]*P_[tag,k_local]*beta_backward[tag,k_local];\n            }\n          }\n          q_transition[tag,,]=q_transition[tag,,]/sum(q_transition[tag,,]) # normalize\n        }\n      }\n      q_tran_sum =  matrix(rep(0,K*K),K); #To calculate the first sum in S8 to update global phi_A\n      for(tag in (j+1):(j+sub_length-1))\n      {\n        q_tran_sum=q_tran_sum+q_transition[tag,,];\n      }\n      q_x_sum1 = matrix(rep(0,K*Dim),Dim)#To calculate the second sum in S8, and paper is wrong in notation\n      for(k_local in 1:K)\n      {\n        for(tag in j:(j+sub_length-1))\n        {\n          q_x_sum1[,k_local]=q_x_sum1[,k_local]+q_x[tag,k_local]*Data_sequence[[tag]]\n        }\n      }\n      q_x_sum2 = rep(0,K);\n      for(tag in j:(j+sub_length-1)) #To calculate the third sum in S8\n      {\n        q_x_sum2=q_x_sum2+q_x[tag,]\n      }\n      q_x_sum4 = q_x_sum2\n      q_x_sum3 = array(rep(0,K*Dim*Dim),c(K,Dim,Dim))\n      for(k_local in 1:K) # To calculate the fourth sum in S8\n      {\n        for(tag in j:(j+sub_length-1))\n        {\n          q_x_sum3[k_local,,]=q_x_sum3[k_local,,]+q_x[tag,k_local]*Data_sequence[[tag]]%*%t(Data_sequence[[tag]])\n        }\n      }\n      # 调和数列\n      W_A = ((1-((i-1)*(T-sub_length+1)+j)^(-1))*W_A\n             +((i-1)*(T-sub_length+1)+j)^(-1)*(((T-sub_length+1)/(sub_length-1))*q_tran_sum+U_A))\n      u = (1-((i-1)*(T-sub_length+1)+j)^(-1))*u+((i-1)*(T-sub_length+1)+j)^(-1)*((T-sub_length+1)/sub_length*q_x_sum1+U_phi1)\n      k = (1-((i-1)*(T-sub_length+1)+j)^(-1))*k+((i-1)*(T-sub_length+1)+j)^(-1)*((T-sub_length+1)/sub_length*q_x_sum2+U_phi2)\n      for(i_local in 1:K)\n      {\n        sigma[[i_local]]=(1-((i-1)*(T-sub_length+1)+j)^(-1))*sigma[[i_local]]+((i-1)*(T-sub_length+1)+j)^(-1)*((T-sub_length+1)/sub_length*q_x_sum3[i_local,,]+U_phi3[[i_local]])\n      }\n      v = (1-((i-1)*(T-sub_length+1)+j)^(-1))*v+((i-1)*(T-sub_length+1)+j)^(-1)*((T-sub_length+1)/sub_length*q_x_sum4+U_phi4)\n      write.table(W_A,\"W_A.txt\",append = T)\n      write.table(u,\"u.txt\",append = T)\n      write.table(k,\"k.txt\",append = T)\n      write.table(sigma,\"sigma.txt\",append = T)\n      write.table(v,\"v.txt\",append = T)\n    }\n  }\n  return(q_transition)\n}\ndata <-list(c(1.8,2.0),c(1,2),c(1.1,1.6),c(1.7,1.7),c(1,2),c(1.1,1.6),c(1,2),c(1.1,1.6),c(1.7,1.7),c(1,2),c(1.1,1.6),c(2,4),c(3,3))\nK=2\nDim=length(data[[1]])# Gassiuan Component Number\nalpha=1/K        #\nu0 = 1:Dim # initial mean value\nk0=1             # initial parameter\nv0=6             # initial parameter\nsigma0 = diag(rep(1,2)) # initial covariance with identity matrix\nU_A = matrix(rep(1/K,K*K),K)        # Hyperperameter the same notation with the paper\nU_phi1 = matrix(rep(0,Dim*K),Dim) # Hyperperameter the same notation with the paper\nfor(i in 1:K)\n{\n  U_phi1[,i]=2*k0*u0;\n}\nU_phi2 = rep(2*k0,K)    # Hyperperameter the same notation with the paper\nU_phi3 = list(K)\nfor(i in 1:K)\n{\n  U_phi3[[i]]=  sigma0+2*k0*u0%*%t(u0);           # initial every component with the same covariance\n}\nU_phi4 = rep(v0+2+2,K)  # Hyperperameter the same notation with the paper\nsub_length = 5   # sample chain length  # data_dimention\nu = matrix(rep(0,Dim*K),Dim) ;  # claim mean value of K components.\nk = 1:K;                  # claim k, which controls Gussuian Distribution\nv = (3+Dim):(2+Dim+K);                  # claim v, which controls Gussuian Distribution\nfor( i in 1:K)\n{\n  u[,i]=i*u0;                    # initial every component with the same mean value\n}\nsigma = list(K)\nfor(i in 1:K)\n{\n  sigma[[i]]= i*sigma0;         # initial every component with the same covariance\n}\nW_A = matrix(1:(K*K),K);\nresult = SVI.HMM(data,sub_length =13,K=2,W_A, u, k, sigma, v, U_A, U_phi1,U_phi2, U_phi3, U_phi4, Pass=100, pre=0.01)\n",
    "created" : 1503240758311.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "439594035",
    "id" : "F6416ACE",
    "lastKnownWriteTime" : 1503262192,
    "last_content_update" : -2147483648,
    "path" : "D:/Rproject/SVI.LDA.HMM/R/test.R",
    "project_path" : "R/test.R",
    "properties" : {
        "source_window_id" : "",
        "tempName" : "Untitled1"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}